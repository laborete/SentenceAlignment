{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from __future__ import unicode_literals \n",
    "import nltk\n",
    "import re\n",
    "from bosonnlp import BosonNLP\n",
    "nlp = BosonNLP('Yy7Tpb83.27824.Zdrfgp6JtKTf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.cursor.Cursor at 0x1113085f8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.grant.find({\"patentNumber\":\"9532494\"},{\"patentNumber\":1, \"abstractText\":1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "myclient = pymongo.MongoClient(\"mongodb://140.112.106.212:27017/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dblist = myclient.list_database_names()\n",
    "if \"us\" in dblist:\n",
    "    mydb = myclient[\"us\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "collist = mydb.list_collection_names()\n",
    "if \"grant\" in collist:\n",
    "    mycol = mydb[\"grant\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "patents = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97531\n"
     ]
    }
   ],
   "source": [
    "for x in mycol.find({},{\"patentNumber\":1, \"abstractText\":1}):\n",
    "    patents.append([x['patentNumber'],x['abstractText']])\n",
    "print(len(patents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('eng_patents.pickle','wb') as f:\n",
    "    pickle.dump(patents,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('eng_patents.pickle','rb') as f:\n",
    "    patents = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def en_regex(a):\n",
    "    #a = re.sub('[a-zA-Z]','',a)\n",
    "    a = re.sub('[{}、「」()：；！？，。－\"\\']','',a)\n",
    "    a = re.sub(',.:;!?',' ',a)\n",
    "    a = re.sub('\\n','',a)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex(a):\n",
    "    a = re.sub('[,、：；！？，。－\"\\']','',a)\n",
    "    a = re.sub('[「」(){}:;!?]','',a)\n",
    "    a = re.sub('\\n','',a)\n",
    "    #a = re.sub('[(),{}\\u3000\\*\\|=-\\[\\]\\n.]','',a)\n",
    "    a = re.sub(u\"\\\\（.*?\\\\）|\\\\『.*?』|\\\\「.*?」|\\\\〔.*?〕|\\\\[.*?]|\\\\〈.*?〉\", '', a)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352253\n"
     ]
    }
   ],
   "source": [
    "sents = []\n",
    "for i in range(0,len(patents)):\n",
    "    tmp = patents[i][1]\n",
    "    tmp = tmp.split('.')\n",
    "    for line in tmp:\n",
    "        if not line == '':\n",
    "            sents.append(en_regex(line.strip().lower()))\n",
    "print(len(sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n",
      "270000\n",
      "280000\n",
      "290000\n",
      "300000\n",
      "310000\n",
      "320000\n",
      "330000\n",
      "340000\n",
      "350000\n",
      "352253\n"
     ]
    }
   ],
   "source": [
    "eng = []\n",
    "for x in range(0,len(sents)):\n",
    "    if x%10000==0:\n",
    "        print(x)\n",
    "    tmpstr = '<bos>/<sos>'\n",
    "    words = nltk.word_tokenize(sents[x])\n",
    "    word_tag = nltk.pos_tag(words)\n",
    "    for i in range(0,len(word_tag)):\n",
    "        tmpstr = tmpstr+' '+word_tag[i][0]+'/'+word_tag[i][1]\n",
    "    tmpstr = tmpstr+' <eos>/<sos>'\n",
    "    eng.append(tmpstr)\n",
    "print(len(eng))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<bos>/<sos> methods/NNS and/CC devices/NNS for/IN biological/JJ sample/NN preparation/NN and/CC analysis/NN are/VBP disclosed/VBN <eos>/<sos>'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng[51515]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('0503英文專利資料.txt', 'w+') as f:\n",
    "    for item in eng:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('英文專利單句.txt', 'w+') as f:\n",
    "    for item in sents:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "tmp = []\n",
    "x = 1\n",
    "for i in range(1,len(sents)):\n",
    "    tmp.append(sents[i-1])\n",
    "    if i%100==0 or i==len(sents):\n",
    "        with open('EngPatentSents/epsents'+str(x)+'.txt', 'w+') as f:\n",
    "            for item in tmp:\n",
    "                f.write(\"%s\\n\" % item)\n",
    "            tmp = []\n",
    "            x = x+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "testen = []\n",
    "testch = []\n",
    "tmp = []\n",
    "tmp2 = []\n",
    "for i in range(1,100):\n",
    "    with open('0505/epsents'+str(i)+'.txt', 'r') as f:\n",
    "        for line in f:\n",
    "            tmp.append(line)\n",
    "    with open('0505/'+str(i)+'.txt', 'r') as f:\n",
    "        for line in f:\n",
    "            tmp2.append(line)\n",
    "    if len(tmp) == len(tmp2):\n",
    "        for line in tmp:\n",
    "            testen.append(line)\n",
    "        for line in tmp2:\n",
    "            testch.append(line)\n",
    "        tmp = []\n",
    "        tmp2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9900 9900\n"
     ]
    }
   ],
   "source": [
    "print(len(testen),len(testch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3389"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = []\n",
    "for i in range(0,len(testen)):\n",
    "    if len(testen[i].split()) <=20 and len(testen[i].split()) >= 10:\n",
    "        outputs.append([en_regex(testen[i]),regex(testch[i])])\n",
    "len(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['each blade includes a blade processor and a plurality of smart couplers',\n",
       " '每個刀片包括刀片處理器和多個智能耦合器']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish 1 sentences\n",
      "finish 101 sentences\n",
      "finish 201 sentences\n",
      "finish 301 sentences\n",
      "finish 401 sentences\n",
      "finish 501 sentences\n",
      "finish 601 sentences\n",
      "finish 701 sentences\n",
      "finish 801 sentences\n",
      "finish 901 sentences\n",
      "finish 1001 sentences\n",
      "finish 1101 sentences\n",
      "finish 1201 sentences\n",
      "finish 1301 sentences\n",
      "finish 1401 sentences\n",
      "finish 1501 sentences\n",
      "finish 1601 sentences\n",
      "finish 1701 sentences\n",
      "finish 1801 sentences\n",
      "finish 1901 sentences\n",
      "finish 2001 sentences\n",
      "finish 2101 sentences\n",
      "finish 2201 sentences\n",
      "finish 2301 sentences\n",
      "finish 2401 sentences\n",
      "finish 2501 sentences\n",
      "finish 2601 sentences\n",
      "finish 2701 sentences\n",
      "finish 2801 sentences\n",
      "finish 2901 sentences\n",
      "finish 3001 sentences\n",
      "finish 3101 sentences\n",
      "finish 3201 sentences\n",
      "finish 3301 sentences\n"
     ]
    }
   ],
   "source": [
    "cboson = []\n",
    "tag_boson = []\n",
    "tmp = ''\n",
    "start = 0\n",
    "for i in range(0,len(outputs)):\n",
    "    try:\n",
    "        result = nlp.tag(outputs[i][1])\n",
    "        for word in result[0]['word']:\n",
    "            tmp = tmp+word+'#'\n",
    "        cboson.append(tmp)\n",
    "        tmp = ''\n",
    "        for tag in result[0]['tag']:\n",
    "            tmp = tmp+tag+'#'\n",
    "        tag_boson.append(tmp)\n",
    "        tmp = ''\n",
    "    except:\n",
    "        print('summary',i,'does not work.')\n",
    "    start = start+1\n",
    "    if(i%100==0):\n",
    "        print('finish',start,'sentences')\n",
    "        #print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n"
     ]
    }
   ],
   "source": [
    "engs = []\n",
    "for x in range(0,len(outputs)):\n",
    "    if x%1000==0:\n",
    "        print(x)\n",
    "    tmpstr = '<bos>/<sos>'\n",
    "    words = nltk.word_tokenize(outputs[x][0])\n",
    "    word_tag = nltk.pos_tag(words)\n",
    "    for i in range(0,len(word_tag)):\n",
    "        tmpstr = tmpstr+' '+word_tag[i][0]+'/'+word_tag[i][1]\n",
    "    tmpstr = tmpstr+' <eos>/<sos>'\n",
    "    engs.append(tmpstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi = []\n",
    "for x in range(0,len(cboson)):\n",
    "    a = cboson[x].split('#')\n",
    "    b = tag_boson[x].split('#')\n",
    "    if(len(a)-len(b))==0:\n",
    "        tmpstr = '<bos>/<sos>'\n",
    "        for i in range(0,len(a)-1):\n",
    "            tmpstr = tmpstr+' '+a[i]+'/'+b[i]\n",
    "        tmpstr = tmpstr+' <eos>/<sos>'\n",
    "    else:\n",
    "        tmpstr = '<bos>/<sos>''<eos>/<sos>'\n",
    "        print(x,'Wtf')\n",
    "    chi.append(tmpstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('0505英文直接對應文本.txt', 'w+') as f:\n",
    "    for item in engs:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "        \n",
    "with open('0505中文直接對應文本.txt', 'w+') as f:\n",
    "    for item in chi:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
