{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import csv\n",
    "#import dict_builder as db\n",
    "import re\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "#from __future__ import unicode_literals \n",
    "#from bosonnlp import BosonNLP\n",
    "#nlp = BosonNLP('Yy7Tpb83.27824.Zdrfgp6JtKTf')\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import nltk\n",
    "Porter = nltk.stem.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_serving.client import BertClient\n",
    "from scipy import spatial\n",
    "bc = BertClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readfile(filename,method='utf-8'):\n",
    "    rawlist = []\n",
    "    with open(filename,'r+', encoding=method) as csvfile:\n",
    "        rows = csv.reader(csvfile)\n",
    "        for row in rows:\n",
    "            rawlist.append(row)\n",
    "    return rawlist\n",
    "\n",
    "def writefile(filename,inputlist,method='utf-8'):\n",
    "    with open(filename,'a+', encoding=method) as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "        for row in inputlist:\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex(a):\n",
    "    reg = []\n",
    "    #a = re.sub('[a-zA-Z]','',a)\n",
    "    a = re.sub('[,、：；！？，。－\"\\']','#',a)\n",
    "    a = re.sub('[「」(){}:;!?]','',a)\n",
    "    a = re.sub('\\n','',a)\n",
    "    #a = re.sub('[(),{}\\u3000\\*\\|=-\\[\\]\\n.]','',a)\n",
    "    #a = re.sub(u\"\\\\（.*?\\\\）|\\\\『.*?』|\\\\「.*?」|\\\\〔.*?〕|\\\\[.*?]|\\\\〈.*?〉\", '', a)\n",
    "    reg = a.split('#')\n",
    "    return reg\n",
    "\n",
    "def en_regex(a):\n",
    "    reg = []\n",
    "    #a = re.sub('[a-zA-Z]','',a)\n",
    "    a = re.sub('[{}.:;!?：；！？，。－\"\\']','#',a)\n",
    "    a = re.sub('[、「」()]','',a)\n",
    "    a = re.sub(',',' ',a)\n",
    "    a = re.sub('\\n','',a)\n",
    "    #a = re.sub('[(),{}\\u3000\\*\\|=-\\[\\]\\n.]','',a)\n",
    "    #a = re.sub(u\"\\\\（.*?\\\\）|\\\\『.*?』|\\\\「.*?」|\\\\〔.*?〕|\\\\[.*?]|\\\\〈.*?〉\", '', a)\n",
    "    reg = a.split('#')\n",
    "    return reg\n",
    "\n",
    "def isEnglish(s):\n",
    "    try:\n",
    "        s.encode(encoding='utf-8').decode('ascii')\n",
    "    except UnicodeDecodeError:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 從這裡開始跑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chcut = []\n",
    "with (open('chcut.pickle', \"rb\")) as openfile:\n",
    "    chcut = pickle.load(openfile)\n",
    "encut = []\n",
    "with (open('encut.pickle', \"rb\")) as openfile:\n",
    "    encut = pickle.load(openfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用不到"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ch_dic = {}\n",
    "for i in range(0,len(chcut)):\n",
    "    for j in range(0,len(chcut[i])):\n",
    "        for word in chcut[i][j]:\n",
    "            if ch_dic.get(word) == None:\n",
    "                ch_dic[word] = [i]\n",
    "            else:\n",
    "                if i not in ch_dic[word]: \n",
    "                    ch_dic[word].append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tmp = []\n",
    "encut = []\n",
    "for i in range(0,len(alignment)):\n",
    "    for sent in alignment[i][1]:\n",
    "        tmp.append(sent.split())\n",
    "    encut.append(tmp)\n",
    "    tmp = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "en_dic = {}\n",
    "for i in range(0,len(encut)):\n",
    "    for j in range(0,len(encut[i])):\n",
    "        for word in encut[i][j]:\n",
    "            #word = Porter.stem(word)\n",
    "            if en_dic.get(word) == None:\n",
    "                en_dic[word] = [i]\n",
    "            else:\n",
    "                if i not in en_dic[word]: \n",
    "                    en_dic[word].append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bertvectors = {}\n",
    "for i in range(0,len(encut)):\n",
    "    if i%50==0:\n",
    "        print(i)\n",
    "    for j in range(0,len(encut[i])):\n",
    "        for word in encut[i][j]:\n",
    "            #word = Porter.stem(word)\n",
    "            #print(word)\n",
    "            if not word in bertvectors:\n",
    "                if not word == '':\n",
    "                    bertvectors[word] = bc1.encode([word])\n",
    "                    \n",
    "for i in range(0,len(chcut)):\n",
    "    if i%50==0:\n",
    "        print(i)\n",
    "    for j in range(0,len(chcut[i])):\n",
    "        for word in chcut[i][j]:\n",
    "            try:\n",
    "                tmp = adict[word]\n",
    "            except:\n",
    "                tmp = [word]\n",
    "            for meaning in tmp:\n",
    "                if meaning not in bertvectors:\n",
    "                    if not meaning == '':\n",
    "                        bertvectors[meaning] = bc.encode([meaning])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#計算有幾個match的文章\n",
    "def co_occur(list1,list2):\n",
    "    return len(list(set(list1).intersection(list2)))\n",
    "\n",
    "ch_dic_freq = []\n",
    "for key in ch_dic:\n",
    "    ch_dic_freq.append(len(ch_dic[key]))\n",
    "ch_dic_freq_mean = np.mean(ch_dic_freq)\n",
    "ch_dic_freq_sd = np.std(ch_dic_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def ch_weight(list1):\n",
    "    list2 = []\n",
    "    rlist = []\n",
    "    for word in list1:\n",
    "        list2.append([len(ch_dic[word]),word])\n",
    "    list2 = sorted(list2,reverse=True)\n",
    "    #print(list1)\n",
    "    for i in range(0,len(list1)):\n",
    "        for j in range(0,len(list2)):\n",
    "            if list1[i] == list2[j][1]:\n",
    "                rlist.append(j+1)\n",
    "                #print(list1[i],j+1)\n",
    "                break\n",
    "    return(rlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def s2s_calculator(cs,es,chdic=ch_dic,endic=en_dic):\n",
    "    s2s_rate = 0\n",
    "    w2s_rate = 0\n",
    "    rank = ch_weight(cs)\n",
    "    weightsum = sum(rank)\n",
    "    \n",
    "    for i in range(0,len(cs)):    \n",
    "        for en_word in es:\n",
    "            numerator = co_occur(chdic[cs[i]],endic[Porter.stem(en_word)])\n",
    "            denominator = len(chdic[cs[i]])+len(endic[Porter.stem(en_word)])-numerator\n",
    "            w2w_rate = float(numerator/denominator)\n",
    "            if w2w_rate>w2s_rate:\n",
    "                #w2s_rate += float(w2w_rate/len(es))\n",
    "                w2s_rate = w2w_rate\n",
    "        s2s_rate += float(w2s_rate*(rank[i]/weightsum))\n",
    "        #print(cs[i],rank[i]/weightsum,w2s_rate,s2s_rate)\n",
    "        w2s_rate = 0\n",
    "        w2w_rate = 0\n",
    "    return(s2s_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def another_s2s_calculator(cs,es,chdic=ch_dic,endic=en_dic):\n",
    "    s2s_rate = 0\n",
    "    w2s_rate = 0\n",
    "    counter = 0\n",
    "    for i in range(0,len(cs)):\n",
    "        if not len(chdic[cs[i]])>(ch_dic_freq_mean+5*ch_dic_freq_sd):\n",
    "            for en_word in es:\n",
    "                numerator = co_occur(chdic[cs[i]],endic[Porter.stem(en_word)])\n",
    "                denominator = len(chdic[cs[i]])+len(endic[Porter.stem(en_word)])-numerator\n",
    "                w2w_rate = float(numerator/denominator)\n",
    "                if w2w_rate>w2s_rate:\n",
    "                    #w2s_rate += float(w2w_rate/len(es))\n",
    "                    w2s_rate = w2w_rate\n",
    "            counter = counter+1\n",
    "            s2s_rate += float(w2s_rate)\n",
    "            #print(cs[i],counter,w2s_rate,(s2s_rate/counter))\n",
    "            w2s_rate = 0\n",
    "            w2w_rate = 0\n",
    "    if not counter==0:\n",
    "        return(s2s_rate/counter)\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 開始用的到"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38148"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('bertvectors1.pickle', 'rb') as file:\n",
    "    tmpd1 = pickle.load(file)\n",
    "with open('bertvectors2.pickle', 'rb') as file:\n",
    "    tmpd2 = pickle.load(file)\n",
    "with open('bertvectors3.pickle', 'rb') as file:\n",
    "    tmpd3 = pickle.load(file)\n",
    "with open('bertvectors4.pickle', 'rb') as file:\n",
    "    tmpd4 = pickle.load(file)\n",
    "bertvectors = {**tmpd1, **tmpd2, **tmpd3, **tmpd4}\n",
    "len(bertvectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17209"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('chinese_bertvectors.pickle', 'rb') as file:\n",
    "    chinese_bertvectors = pickle.load(file)\n",
    "len(chinese_bertvectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114442"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adictsrc = readfile('zh_en_dict.csv')\n",
    "adict = dict()\n",
    "for i in range(0,len(adictsrc)):\n",
    "    adict[adictsrc[i][0]] = adictsrc[i][1:]\n",
    "len(adict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 768)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('trans_matrix.pickle', 'rb') as file:\n",
    "    transmatrix = pickle.load(file)\n",
    "np.shape(transmatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bert 相似度演算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_calculator(cs,es):\n",
    "    s2s_rate = 0\n",
    "    for i in range(0,len(cs)):\n",
    "        try:\n",
    "            translations = adict[cs[i]]\n",
    "        except:\n",
    "            translations = [cs[i]]\n",
    "        tmpcossim = 0\n",
    "        #print('*',translations)\n",
    "        for trans in translations:\n",
    "            #print(trans)\n",
    "            if not trans == '':\n",
    "                try:\n",
    "                    bert_ch = bertvectors[trans]\n",
    "                except:\n",
    "                    bert_ch = bc.encode([trans])\n",
    "                for en_word in es:\n",
    "                    try:\n",
    "                        bert_en = bertvectors[en_word]\n",
    "                    except:\n",
    "                        bert_en = bc.encode([en_word])\n",
    "                    teststat = 1-spatial.distance.cosine(bert_en,bert_ch)\n",
    "                    #print(trans,'/',en_word,teststat)\n",
    "                    if (teststat > tmpcossim):\n",
    "                        tmpcossim = teststat\n",
    "        s2s_rate = s2s_rate + tmpcossim\n",
    "    if(len(cs))==0:\n",
    "        return 0\n",
    "    s2s_rate = float(s2s_rate/len(cs))\n",
    "    return(s2s_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bert 相似度演算法（利用轉置矩陣）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_matrix(cs,es):\n",
    "    s2s_rate = 0\n",
    "    for i in range(0,len(cs)):\n",
    "        ch_word = cs[i]\n",
    "        tmpcossim = 0\n",
    "        if not ch_word == '':\n",
    "            try:\n",
    "                bert_ch = chinese_bertvectors[ch_word]\n",
    "            except:\n",
    "                bert_ch = bc.encode([ch_word])\n",
    "            bert_ch = np.dot(bert_ch,transmatrix)\n",
    "            for en_word in es:\n",
    "                try:\n",
    "                    bert_en = bertvectors[en_word]\n",
    "                except:\n",
    "                    bert_en = bc.encode([en_word])\n",
    "                teststat = 1-spatial.distance.cosine(bert_en,bert_ch)\n",
    "                #print(teststat)\n",
    "                if (teststat > tmpcossim):\n",
    "                    tmpcossim = teststat\n",
    "        s2s_rate = s2s_rate + tmpcossim\n",
    "    if(len(cs))==0:\n",
    "        return 0\n",
    "    s2s_rate = float(s2s_rate/len(cs))\n",
    "    return(s2s_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_your_algo(c,e,method='bert'):\n",
    "    rate = 0\n",
    "    if method=='rank':\n",
    "        rate = s2s_calculator(c,e)\n",
    "    elif method=='average':\n",
    "        rate = another_s2s_calculator(c,e,chdic,endic)\n",
    "    elif method=='bert':\n",
    "        rate = bert_calculator(c,e)\n",
    "    elif method=='matrix':\n",
    "        rate = bert_matrix(c,e)    \n",
    "    return rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_output_combination(c,e,i,k):\n",
    "    ctmp = ''\n",
    "    etmp = ''\n",
    "    for word in c:\n",
    "        ctmp = ctmp + word\n",
    "    for word in e:\n",
    "        etmp = etmp+' '+word\n",
    "    comber = str(i)\n",
    "    for ktop in range(1,k):\n",
    "        comber = comber +'+'+ str(i+ktop)\n",
    "    return ctmp,etmp,comber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_variables(i,k,j):\n",
    "    igate = i+k\n",
    "    jgate = j+1\n",
    "    ceiling = 0\n",
    "    rate = 0\n",
    "    return igate,jgate,ceiling,rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_operations(ceiling,tmp,en,i,k,j):\n",
    "    ctmp,etmp,combstr = word_output_combination(tmp,en,i,k)\n",
    "    if len(combstr)>1:\n",
    "        print('Combination of {0}'.format(combstr))\n",
    "    print('R:{0:4f}\\nC:{1}\\nE:{2}\\n'.format(ceiling,ctmp,etmp))\n",
    "    igate,jgate,ceiling,rate = reset_variables(i,k,j)\n",
    "    return ctmp,etmp,igate,jgate,ceiling,rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# greedy linear 演算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy(chlist,enlist,method='bert',threshold=0.85):\n",
    "    igate = 0\n",
    "    jgate = 0\n",
    "    ceiling = 0\n",
    "    rate = 0\n",
    "    output = []\n",
    "    ctmp = ''\n",
    "    etmp = ''\n",
    "    for i in range(0,len(chlist)):\n",
    "        tmp = ''\n",
    "        if i>=igate:\n",
    "            for j in range(jgate,i+5):\n",
    "                if j<len(enlist) and j>=0:\n",
    "                    rate = choose_your_algo(chlist[i],enlist[j],method)    \n",
    "                    ceiling = rate\n",
    "                    #print(i,j,rate)\n",
    "                    if rate>threshold:\n",
    "                        tmp = chlist[i]\n",
    "                        #print(tmp)\n",
    "                        for k in range(1,5):\n",
    "                            if (i+k)<len(chlist):\n",
    "                                rate = choose_your_algo((tmp+chlist[i+k]),enlist[j],method)\n",
    "                               \n",
    "                                if rate > ceiling:\n",
    "                                    tmp = tmp + chlist[i+k]\n",
    "                                    ceiling = rate\n",
    "                                    #print(tmp)\n",
    "                                    if k==4:\n",
    "                                    #Window用完\n",
    "                                        ctmp,etmp,igate,jgate,ceiling,rate = greedy_operations(ceiling,\n",
    "                                                                                           tmp,enlist[j],i,k,j)\n",
    "                                        output.append([ctmp,etmp])\n",
    "                                        break\n",
    "                                else:\n",
    "                                #結果沒變好直接吐出值\n",
    "                                    ctmp,etmp,igate,jgate,ceiling,rate = greedy_operations(ceiling,\n",
    "                                                                                           tmp,enlist[j],i,k,j)\n",
    "                                    output.append([ctmp,etmp])\n",
    "                                    break\n",
    "                            else:\n",
    "                            #中文用完\n",
    "                                ctmp,etmp,igate,jgate,ceiling,rate = greedy_operations(ceiling,\n",
    "                                                                                           tmp,enlist[j],i,k,j)\n",
    "                                output.append([ctmp,etmp])\n",
    "                                break\n",
    "                        break\n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_template = [['本','論文','主要','討論','機器','學習'],['機器人','在','現代'],['對','人類','很','重要'],['同時','電腦','也','很','重要'],['我','喜歡','論文']]\n",
    "en_template = [['This','paper','mainly','discuss','machine','learning'],['Robots','are','important','to','people','nowadays','and','so','do','computers'],['I','like','paper']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0.7630445443170895\n",
      "0 1 0.780333444938179\n",
      "0 2 0.7790630640172993\n",
      "1 0 0.7429939604586964\n",
      "1 1 0.763077076752844\n",
      "1 2 0.7583879150335374\n",
      "2 0 0.7566632295554431\n",
      "2 1 0.7762826827317164\n",
      "2 2 0.7740580276648825\n",
      "3 0 0.7537466386469027\n",
      "3 1 0.774404109432125\n",
      "3 2 0.7752456838927191\n",
      "4 0 0.7724206424658083\n",
      "4 1 0.8008964808373603\n",
      "4 2 0.7916654306340094\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(ch_template)): \n",
    "    for j in range(0,len(en_template)):\n",
    "        print(i,j,bert_matrix(ch_template[i],en_template[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R:0.903871\n",
      "C:本論文主要討論機器學習\n",
      "E: This paper mainly discuss machine learning\n",
      "\n",
      "R:0.880259\n",
      "C:對人類很重要\n",
      "E: Robots are important to people nowadays and so do computers\n",
      "\n",
      "R:0.885927\n",
      "C:我喜歡論文\n",
      "E: I like paper\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['本論文主要討論機器學習', ' This paper mainly discuss machine learning'],\n",
       " ['對人類很重要', ' Robots are important to people nowadays and so do computers'],\n",
       " ['我喜歡論文', ' I like paper']]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greedy(ch_template,en_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Comparing set 10 using bert-----\n",
      "R:0.840216\n",
      "C:含計數量詞的二階邏輯C2有著許多應用\n",
      "E: It is well known that the satisfiability problem for C2 is decidable in nondeterministic exponential time NEXPTIME and the complexity is optimal\n",
      "\n",
      "R:0.838386\n",
      "C:一個著名的結果是\n",
      "E: However the known techniques are quite complicated and they typically involve guessing a structure or a representation that satisfies the input formula which can be hard to implement\n",
      "\n",
      "-----Comparing set 11 using bert-----\n",
      "Combination of 3+4\n",
      "R:0.839113\n",
      "C:並使用文字來表示網路服務和進行比對因此文字比對的準確性會對服務比對的表現造成很大的影響\n",
      "E: In text-based service matchmaking approach since the web service is treated as a plain text and use term tokens as the internal representation to match services the accuracy of the text comparison will affect the performance of service matchmaking\n",
      "\n",
      "R:0.843955\n",
      "C:2.從參考資料中取得文字關係\n",
      "E: An experiment is also conducted based on an OWLS-TC V4 service matchmaking benchmark with hypothesis testing to compare our proposed approach with the iSeM approach\n",
      "\n",
      "-----Comparing set 12 using bert-----\n",
      "R:0.835084\n",
      "C:優雅而不羅嗦\n",
      "E: Writing in a professional or formal context requires conciseness\n",
      "\n",
      "R:0.848106\n",
      "C:經過刪簡精練\n",
      "E: Starting from a colloquial draft text is gradually refined and wordiness removed resulting in a more formal style\n",
      "\n",
      "R:0.838151\n",
      "C:刪字刪詞是新聞改稿最頻繁的動作之一\n",
      "E: For newspaper editing this is among the most frequent operations yet is still carried out manually\n",
      "\n",
      "-----Comparing set 13 using bert-----\n",
      "Combination of 1+2\n",
      "R:0.831506\n",
      "C:股市指數通常由多家上市公司的股票組合而成然而其價格決定於複雜的交易過程\n",
      "E: A stock index consists of a board selection of stocks\n",
      "\n",
      "R:0.832930\n",
      "C:市場高頻資料每5秒包含了2015年至2017年日內的臺灣加權指數與個股價格\n",
      "E: Therefore predicting the direction of an index involves modeling and analyzing sophisticated multi-dimensional time series\n",
      "\n",
      "-----Comparing set 14 using bert-----\n"
     ]
    }
   ],
   "source": [
    "for i in range(10,15):\n",
    "    print('-----Comparing set {0} using bert-----'.format(i))\n",
    "    greedy(chcut[i],encut[i],method='matrix',threshold=0.83)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Comparing set 10 using bert-----\n",
      "Combination of 1+2\n",
      "R:0.893147\n",
      "C:含計數量詞的二階邏輯C2有著許多應用特別像是本體知識語言的應用\n",
      "E: Two variable logic with counting quantifiers C2 has found many applications especially in ontology language such as OWL used in semantic web\n",
      "\n",
      "R:0.879203\n",
      "C:C2的可滿足性問題可以在非確定性指數時間NEXPTIME內決定\n",
      "E: It is well known that the satisfiability problem for C2 is decidable in nondeterministic exponential time NEXPTIME and the complexity is optimal\n",
      "\n",
      "R:0.884200\n",
      "C:而且這樣的複雜度是最佳的\n",
      "E: However the known techniques are quite complicated and they typically involve guessing a structure or a representation that satisfies the input formula which can be hard to implement\n",
      "\n",
      "-----Comparing set 11 using bert-----\n",
      "R:0.909035\n",
      "C:在text-based的網路服務比對方法中\n",
      "E: In text-based service matchmaking approach since the web service is treated as a plain text and use term tokens as the internal representation to match services the accuracy of the text comparison will affect the performance of service matchmaking\n",
      "\n",
      "R:0.855585\n",
      "C:因此文字比對的準確性會對服務比對的表現造成很大的影響\n",
      "E: An experiment is also conducted based on an OWLS-TC V4 service matchmaking benchmark with hypothesis testing to compare our proposed approach with the iSeM approach\n",
      "\n",
      "-----Comparing set 12 using bert-----\n",
      "R:0.908443\n",
      "C:專業或正式寫作須精簡\n",
      "E: Writing in a professional or formal context requires conciseness\n",
      "\n",
      "R:0.890687\n",
      "C:從口語化的初稿開始\n",
      "E: Starting from a colloquial draft text is gradually refined and wordiness removed resulting in a more formal style\n",
      "\n",
      "R:0.856836\n",
      "C:成為書面而正式的文章\n",
      "E: For newspaper editing this is among the most frequent operations yet is still carried out manually\n",
      "\n",
      "-----Comparing set 13 using bert-----\n",
      "Combination of 1+2\n",
      "R:0.859618\n",
      "C:股市指數通常由多家上市公司的股票組合而成然而其價格決定於複雜的交易過程\n",
      "E: We employ the convolutional neural network to forecast the intra-day price movement of the Taiwan Stock Exchange Weighted Index TAIEX\n",
      "\n",
      "R:0.897743\n",
      "C:並實證模型的預測性\n",
      "E: Furthermore we verify the prediction performance of our model on the high-frequency data 5 sec of the TAIEX and its constituent share prices from 2015 to 2017\n",
      "\n",
      "-----Comparing set 14 using bert-----\n",
      "R:0.903210\n",
      "C:文本分類問題是自然語言處理中的一類問題目標是學習一個模型可以去理解句子的語意進而去分類出不同類別\n",
      "E: Text classification is a specific task in natural language processing that aims at learning a model to know the meaning of given sentences\n",
      "\n",
      "R:0.890713\n",
      "C:雖然現今深度類神經網路越來越熱門並且被應用到各式各樣的領域包括自然語言處理也有許多研究在討論深度模型脆弱的地方\n",
      "E: While deep neural network is becoming more and more popular and be widely used in many domain including natural language processing nowadays there are some works discussing the vulnerability of deep models\n",
      "\n",
      "R:0.854047\n",
      "C:藉由一種人工產生的資料──對抗樣本adversarialexample某方面說明了一個機器學習模型的弱點\n",
      "E: Adversarial examples a kind of synthetic data somehow show the weakness of a machine learning model\n",
      "\n",
      "R:0.872370\n",
      "C:在這篇論文中我們試圖去改進文本分類問題中的對抗樣本尋找方法\n",
      "E: In this work we aim to improve the efficiency of finding adversarial examples in text classification tasks\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10,15):\n",
    "    print('-----Comparing set {0} using bert-----'.format(i))\n",
    "    greedy(chcut[i],encut[i],method='bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Comparing set 10 using bert-----\n",
      "R:0.883479\n",
      "C:含計數量詞的二階邏輯C2有著許多應用\n",
      "E: Two variable logic with counting quantifiers C2 has found many applications especially in ontology language such as OWL used in semantic web\n",
      "\n",
      "R:0.859864\n",
      "C:特別像是本體知識語言的應用\n",
      "E: It is well known that the satisfiability problem for C2 is decidable in nondeterministic exponential time NEXPTIME and the complexity is optimal\n",
      "\n",
      "R:0.884200\n",
      "C:而且這樣的複雜度是最佳的\n",
      "E: However the known techniques are quite complicated and they typically involve guessing a structure or a representation that satisfies the input formula which can be hard to implement\n",
      "\n",
      "-----Comparing set 11 using bert-----\n",
      "R:0.909035\n",
      "C:在text-based的網路服務比對方法中\n",
      "E: In text-based service matchmaking approach since the web service is treated as a plain text and use term tokens as the internal representation to match services the accuracy of the text comparison will affect the performance of service matchmaking\n",
      "\n",
      "R:0.855585\n",
      "C:因此文字比對的準確性會對服務比對的表現造成很大的影響\n",
      "E: An experiment is also conducted based on an OWLS-TC V4 service matchmaking benchmark with hypothesis testing to compare our proposed approach with the iSeM approach\n",
      "\n",
      "-----Comparing set 12 using bert-----\n",
      "R:0.908443\n",
      "C:專業或正式寫作須精簡\n",
      "E: Writing in a professional or formal context requires conciseness\n",
      "\n",
      "R:0.890687\n",
      "C:從口語化的初稿開始\n",
      "E: Starting from a colloquial draft text is gradually refined and wordiness removed resulting in a more formal style\n",
      "\n",
      "R:0.856836\n",
      "C:成為書面而正式的文章\n",
      "E: For newspaper editing this is among the most frequent operations yet is still carried out manually\n",
      "\n",
      "-----Comparing set 13 using bert-----\n",
      "R:0.856438\n",
      "C:股市指數通常由多家上市公司的股票組合而成\n",
      "E: We employ the convolutional neural network to forecast the intra-day price movement of the Taiwan Stock Exchange Weighted Index TAIEX\n",
      "\n",
      "R:0.855843\n",
      "C:然而其價格決定於複雜的交易過程\n",
      "E: Furthermore we verify the prediction performance of our model on the high-frequency data 5 sec of the TAIEX and its constituent share prices from 2015 to 2017\n",
      "\n",
      "-----Comparing set 14 using bert-----\n",
      "R:0.903210\n",
      "C:文本分類問題是自然語言處理中的一類問題目標是學習一個模型可以去理解句子的語意進而去分類出不同類別\n",
      "E: Text classification is a specific task in natural language processing that aims at learning a model to know the meaning of given sentences\n",
      "\n",
      "R:0.890713\n",
      "C:雖然現今深度類神經網路越來越熱門並且被應用到各式各樣的領域包括自然語言處理也有許多研究在討論深度模型脆弱的地方\n",
      "E: While deep neural network is becoming more and more popular and be widely used in many domain including natural language processing nowadays there are some works discussing the vulnerability of deep models\n",
      "\n",
      "R:0.854047\n",
      "C:藉由一種人工產生的資料──對抗樣本adversarialexample某方面說明了一個機器學習模型的弱點\n",
      "E: Adversarial examples a kind of synthetic data somehow show the weakness of a machine learning model\n",
      "\n",
      "R:0.872370\n",
      "C:在這篇論文中我們試圖去改進文本分類問題中的對抗樣本尋找方法\n",
      "E: In this work we aim to improve the efficiency of finding adversarial examples in text classification tasks\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10,15):\n",
    "    print('-----Comparing set {0} using bert-----'.format(i))\n",
    "    greedy(chcut[i],encut[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_data = readfile('Bert_evaluation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_eval_src = []\n",
    "e_eval_src = []\n",
    "#while not pin > len(evaluate_data):\n",
    "for i in range(0,len(evaluate_data)):\n",
    "    #length = random.randint(3,15)\n",
    "    #if not pin+length>len(evaluate_data):\n",
    "    c_eval_src.append(evaluate_data[i][2].split('#'))\n",
    "    e_eval_src.append(evaluate_data[i][0].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pin = 0\n",
    "tmp = []\n",
    "tmp2 = []\n",
    "c_eval = []\n",
    "e_eval = []\n",
    "for i in range(0,5):\n",
    "    length = random.randint(5,15)\n",
    "    pin = random.randint(0,len(evaluate_data))\n",
    "    tmp = c_eval_src[pin:pin+length]\n",
    "    tmp2 = e_eval_src[pin:pin+length]\n",
    "    c_eval.append(tmp)\n",
    "    e_eval.append(tmp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c_eval[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n"
     ]
    }
   ],
   "source": [
    "found=0\n",
    "in_between=0\n",
    "for i in range(0,1000):\n",
    "    if i%100==0:\n",
    "        print(i)\n",
    "    score = bert_calculator(c_eval_src[i],e_eval_src[i+2000])\n",
    "    if score>0.85:\n",
    "        found+=1\n",
    "    elif score>0.8:\n",
    "        in_between+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.001\n",
      "Recall(threshold=0.8): 0.151\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall:\",found/1000)\n",
    "print(\"Recall(threshold=0.8):\",(found+in_between)/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Comparing set 0 using bert-----\n",
      "R:0.850348\n",
      "C:隨著IIoT工業物聯網的發展，工廠的自動化系統變得更加開放，動態靈活，適應性強，複雜\n",
      "E: With the development of IIoT Industrial IoT the autonomous system of the factory becomes more open dynamic flexible adaptable and complex\n",
      "\n",
      "R:0.874579\n",
      "C:這些系統的基本安全要求應該意識到負面影響的環境變化，並實施反饋閉環，不斷調整系統的行為\n",
      "E: The fundamental safety requirement of those systems should be aware of the changes in the environment that affect negatively and be implemented the feedback closed loop that continuously adjust the behavior of systems\n",
      "\n",
      "R:0.855538\n",
      "C:在本論文中，為了處理安全運行時監控，我們使用Event-B規範和反應代理模型提出了安全規則的模型驅動方法。\n",
      "E: In this thesis to deal with the safety runtime monitoring we proposed the model-driven approach of the safety rules by using the Event-B specification and reactive agent model\n",
      "\n",
      "R:0.905850\n",
      "C:這種方法使用Event-B的設計從指定受監控系統的安全規則轉變為事件B規範中的設計方法，以支持從安全規則到安全監控代理規則的中間轉換過程\n",
      "E: This approach transforms from specifying the safety rule for the monitored system to the design method in Event-B specification using the design of Event-B to support the intermediate transformation process from the safety rule to the rule of the safety monitoring agent\n",
      "\n",
      "R:0.875231\n",
      "C:我們還提出了我們的監控架構，並參考AGV工業安全標準使用案例研究來測試監控系統\n",
      "E: We also proposed our monitoring architecture and use a case study in reference to AGV industrial safety standard to test the monitoring system\n",
      "\n",
      "R:0.871933\n",
      "C:隨著物聯網技術的成熟，新產品必然具備能夠提供無線數據和監控實時環境環境的能力，並宣告世界將進入智能生活的新時代。\n",
      "E: With the maturation of IoT technology the new products are necessarily equipped with the abilities that can deliver wireless data and monitor real-time environmental circumstance and it also declares that the world is going to enter the new era of intelligent living\n",
      "\n",
      "R:0.865968\n",
      "C:為了保持所收集數據的精確性和完整性，在決定物聯網產品效率時，降低傳感器部分和無線傳輸部分噪聲干擾的能力成為關鍵。\n",
      "E: In order to maintain the precision and integrity of the collected data the ability of reducing noise interferences in both sensor part and wireless transmission part becomes the main point when deciding the efficiency of IoT products\n",
      "\n",
      "-----Comparing set 1 using bert-----\n",
      "R:0.862762\n",
      "C:圓形檯面尺寸半徑為10μm，我們實現了605的高調製帶寬\n",
      "E: With a circular mesa size of 10 μm in radius we achieve the high modulation bandwidth of 605\n",
      "\n",
      "-----Comparing set 2 using bert-----\n",
      "R:0.861665\n",
      "C:然而，BSP具有使用一組預定義的固定波束形成係數可能導致用戶設備UE之間的干擾問題的弱點。\n",
      "E: However the BSP has a weakness that using a set of pre-defined fixed beamforming coefficients can cause the interference problem between user equipments UEs\n",
      "\n",
      "R:0.864606\n",
      "C:因此，本文提出了一種將BSP與協同進化粒子群優化算法相結合的方法，使得設計的波束形成係數可以大大減少UE之間的嚴重干擾。\n",
      "E: Thus this paper proposes a method that incorporates the BSP with a cooperatively coevolving particle swarm optimizationPSO algorithm such that the designed beamforming coefficients can greatly reduce the severe interference between UEs\n",
      "\n",
      "R:0.855817\n",
      "C:這種被稱為BSP-PSO方法的方法不僅可以實現比原始BSP更好的誤碼率BER性能，而且還保留了具有較低的下行鏈路訓練開銷和CSI反饋的BSP的優點。\n",
      "E: This proposed method termed the BSP-PSO method not only can achieve better bit error rate BER performance than the original BSP but also preserves advantages of the BSP having lower overheads of the downlink training and the CSI feedback\n",
      "\n",
      "R:0.869828\n",
      "C:此外，我們基於導出的平均BER公式為這種協同共同進行的PSO提出了一種新的適應度函數\n",
      "E: Additionally we propose a new fitness function for this cooperatively coevolving PSO based on the derived average BER formula\n",
      "\n",
      "R:0.868895\n",
      "C:本論文的主要貢獻包括開發RFID傳感器標籤和開關光束圓極化CP天線陣列作為閱讀器天線，兩者均工作在902-928MHz頻段\n",
      "E: The major contribution of this thesis includes the development of RFID sensor tags and the switched-beam circularly polarized CP antenna array as the reader antenna both of which operate in the 902-928 MHz band\n",
      "\n",
      "R:0.850397\n",
      "C:自適應陣列波束成形技術不僅可以從特定角度提取感興趣的信號，還可以抑制干擾和噪聲\n",
      "E: Adaptive array beamforming is the technique which can not only extracts signals of interest from specific angles but also suppresses interferences and noise\n",
      "\n",
      "R:0.859194\n",
      "C:LCMV線性約束最小方差波束形成器和GSC廣義旁瓣消除器是天線陣列信號處理中的重要技術，需要所需信號的方向作為先驗信息\n",
      "E: LCMVLinearly Constrained Minimum Variance beamformer and GSCGeneralized Sidelobe Canceller are the important techniques in the antenna array signal processing which need the direction of the desired signal as a priori information\n",
      "\n",
      "-----Comparing set 3 using bert-----\n",
      "R:0.855202\n",
      "C:在競爭激烈的商業環境中，協調供應鏈中組織和設施的政策和行為非常重要\n",
      "E: In a competitive business environment it is very important to coordinate the policies and behavior of organizations and facilities in supply chain\n",
      "\n",
      "-----Comparing set 4 using bert-----\n",
      "R:0.884265\n",
      "C:我們使用對數數字系統LNS來簡化計算並提出一種模型壓縮方法，該方法在實驗中大大降低了壓縮比為32所需的存儲量\n",
      "E: We use the Logarithmic Number System LNS to simplify the computations and propose a model compression method that greatly reduces the required storage a compression ratio of 32 in the experiment\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,5):\n",
    "    print('-----Comparing set {0} using bert-----'.format(i))\n",
    "    greedy(c_eval[i],e_eval[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 沒用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c_eval_src = c_eval_src+chcut\n",
    "e_eval_src = e_eval_src+encut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ch_eval_dic = {}\n",
    "for i in range(0,len(c_eval_src)):\n",
    "    for j in range(0,len(c_eval_src[i])):\n",
    "        for word in c_eval_src[i][j]:\n",
    "            if ch_eval_dic.get(word) == None:\n",
    "                ch_eval_dic[word] = [i]\n",
    "                #print(word)\n",
    "            else:\n",
    "                if i not in ch_eval_dic[word]: \n",
    "                    ch_eval_dic[word].append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "en_eval_dic = {}\n",
    "for i in range(0,len(e_eval_src)):\n",
    "    for j in range(0,len(e_eval_src[i])):\n",
    "        for word in e_eval_src[i][j]:\n",
    "            word = Porter.stem(word)\n",
    "            if en_eval_dic.get(word) == None:\n",
    "                en_eval_dic[word] = [i]\n",
    "            else:\n",
    "                if i not in en_eval_dic[word]: \n",
    "                    en_eval_dic[word].append(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
